{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome This project is a 3D engine created as a personal project and coded in C++. The engine features : 3D scene hierarchy manipulation. 3D Graphics abstraction powered by vulkan. Asset compilation to database. Handmade 3D mathematics. Manual manipulation of CPU and GPU memory. For an overview of the engine architecture see architecture overview . What this project can do ? It allows the user to spawn and move 3D nodes in a hierarchical scene. Every node can display a mesh with a material fetched from the asset database or by manually providing asset data. The engine works with an asset database that stores precompiled asset files. An asset database can be fetched by a tool to view it's content. How it's coded ? This project is a learning journey, so as much as possible, it will use handmade solutions (memory containers, maths library, 3D scene management, 3D graphics abstraction, OS interactions). I would like to carry this project as far as possible and take pleasure to build it. So to avoid any frustrations during the development process, every layer of the engine has automated test. This greatly improve the quality of development and debugging sessions. Compared to my other projects, I am focusing more on implementation details and having clean interfaces for every modules before implementing something new. Coding rules These are a set of rules that I have imposed myself for this journey : The standard library is never used (no std::something), every container and algorithms are built from scratch. RAII C++ feature is never used. Memory is manually allocated and deallocated. Inheritance and virtual functions are forbidden. All data structures are plain structs. Singletons are forbidden. If we want to execute an algorithm that involves multiple systems, then these systems must be carried over as function parameters. Forward declarations are forbidden (struct, functions and member functions). The whole codebase is an aggregation of layers, where the Engine structure is at the top. All functions are implemented inline with their definition. As much as possible, avoid nested if statements and consider implementing a specialized version of the function. Aside from memory manipulation, working with raw pointers is forbidden. The codebase works with token instead of pointers. Tokens are essentially indices, it provides safety when the underlying memory is reallocated or moved. To dereference a token, the token must be presented back to the structure that generated it. All these rules enforce a code that is procedural, leveraging C++ template. With this code style, isolation of every layer is trivial and testing every layer is simple (although quite verbose). Third party Usage of third party libraries is limited to : sqlite3 for database The C vulkan headers. glslang for compiling shaders to be understandable by vulkan. stbimage for png loading. (a) Qt for gui tools implementation. (b) (a) There is a work in progress to roll a custom png loader with zlib. Thus removing stbimage for zlib. (b) If one day the engine supports GUI programming, then the Qt dependency can be replaced by it. Try it Both previous engine build used to record gifs are available at the release page . Extract archives and run executables.","title":"Welcome"},{"location":"#welcome","text":"This project is a 3D engine created as a personal project and coded in C++. The engine features : 3D scene hierarchy manipulation. 3D Graphics abstraction powered by vulkan. Asset compilation to database. Handmade 3D mathematics. Manual manipulation of CPU and GPU memory. For an overview of the engine architecture see architecture overview .","title":"Welcome"},{"location":"#what-this-project-can-do","text":"It allows the user to spawn and move 3D nodes in a hierarchical scene. Every node can display a mesh with a material fetched from the asset database or by manually providing asset data. The engine works with an asset database that stores precompiled asset files. An asset database can be fetched by a tool to view it's content.","title":"What this project can do ?"},{"location":"#how-its-coded","text":"This project is a learning journey, so as much as possible, it will use handmade solutions (memory containers, maths library, 3D scene management, 3D graphics abstraction, OS interactions). I would like to carry this project as far as possible and take pleasure to build it. So to avoid any frustrations during the development process, every layer of the engine has automated test. This greatly improve the quality of development and debugging sessions. Compared to my other projects, I am focusing more on implementation details and having clean interfaces for every modules before implementing something new.","title":"How it's coded ?"},{"location":"#coding-rules","text":"These are a set of rules that I have imposed myself for this journey : The standard library is never used (no std::something), every container and algorithms are built from scratch. RAII C++ feature is never used. Memory is manually allocated and deallocated. Inheritance and virtual functions are forbidden. All data structures are plain structs. Singletons are forbidden. If we want to execute an algorithm that involves multiple systems, then these systems must be carried over as function parameters. Forward declarations are forbidden (struct, functions and member functions). The whole codebase is an aggregation of layers, where the Engine structure is at the top. All functions are implemented inline with their definition. As much as possible, avoid nested if statements and consider implementing a specialized version of the function. Aside from memory manipulation, working with raw pointers is forbidden. The codebase works with token instead of pointers. Tokens are essentially indices, it provides safety when the underlying memory is reallocated or moved. To dereference a token, the token must be presented back to the structure that generated it. All these rules enforce a code that is procedural, leveraging C++ template. With this code style, isolation of every layer is trivial and testing every layer is simple (although quite verbose).","title":"Coding rules"},{"location":"#third-party","text":"Usage of third party libraries is limited to : sqlite3 for database The C vulkan headers. glslang for compiling shaders to be understandable by vulkan. stbimage for png loading. (a) Qt for gui tools implementation. (b) (a) There is a work in progress to roll a custom png loader with zlib. Thus removing stbimage for zlib. (b) If one day the engine supports GUI programming, then the Qt dependency can be replaced by it.","title":"Third party"},{"location":"#try-it","text":"Both previous engine build used to record gifs are available at the release page . Extract archives and run executables.","title":"Try it"},{"location":"architecture_overview/","text":"The philosophy of the engine The execution flow of the engine can be seen as a succession of shader pass execution. For example, let's say that the engine needs to allocate some render objects. What the engine does is reading a buffer where is stored all events of allocation and execute them before continuing execution. The whole engine comes together by chaining multiple execution passes in the right order to draw a frame. Execution graph Here is the engine chain of execution represented as a graph: Main loop The main loop is composed of execution units. Execution units are step that trigger all dependant execution block in the order defined by the dependencies. For example, we can see that the Render system is updated when the following execution units are completed : Render resource, Render middleware and the GPU buffer step. Some execution unit within the main loop are called \"user logic\". These execution units are hooks that the engine user can use to execute custom logic at this specific point. Custom logic execution units are likely to create node, add component or move node. Thus, we must be sure that all scene middleware steps are called before the scene tree events are cleaned. Scene An Engine instance is associated to a unique Scene. The Scene is a hierarchical collection of Nodes located in 3D space. Every node can have multiple components attached to them. These components act as a link between the user and the internal systems. See ( scene ). Resources Resources are objects loaded from the asset database. They act as an interface for allocating system objects by taking the asset data as input. Allocations input can either be provided directly by the user or by requesting the asset database. See ( resource ). Scene middleware Scene middlewares are where node component resources are stored. They act as the communication layer between the scene and the internal systems. Because nodes can move in 3D space. The state of the Node is updated when it's position, rotation or scale has changed. The Scene Middlewares are the consumers of this state. When a Node has moved, they send events to internal systems to take this change into account. See ( scene middleware ). Asset management All assets (3DModels, textures, user defined assets...) are stored in a unique local database. Asset files are written either in a human-readable format (.json, .obj, ...) or compressed (.png). However, when stored in the database, they are compiled into a blob that allows the engine to map it to internal objects with little efforts. This compilation is done during the build process, so we eliminate the runtime overhead of loading and decoding file formats. See ( asset database )","title":"Architecture Overview"},{"location":"architecture_overview/#the-philosophy-of-the-engine","text":"The execution flow of the engine can be seen as a succession of shader pass execution. For example, let's say that the engine needs to allocate some render objects. What the engine does is reading a buffer where is stored all events of allocation and execute them before continuing execution. The whole engine comes together by chaining multiple execution passes in the right order to draw a frame.","title":"The philosophy of the engine"},{"location":"architecture_overview/#execution-graph","text":"Here is the engine chain of execution represented as a graph:","title":"Execution graph"},{"location":"architecture_overview/#main-loop","text":"The main loop is composed of execution units. Execution units are step that trigger all dependant execution block in the order defined by the dependencies. For example, we can see that the Render system is updated when the following execution units are completed : Render resource, Render middleware and the GPU buffer step. Some execution unit within the main loop are called \"user logic\". These execution units are hooks that the engine user can use to execute custom logic at this specific point. Custom logic execution units are likely to create node, add component or move node. Thus, we must be sure that all scene middleware steps are called before the scene tree events are cleaned.","title":"Main loop"},{"location":"architecture_overview/#scene","text":"An Engine instance is associated to a unique Scene. The Scene is a hierarchical collection of Nodes located in 3D space. Every node can have multiple components attached to them. These components act as a link between the user and the internal systems. See ( scene ).","title":"Scene"},{"location":"architecture_overview/#resources","text":"Resources are objects loaded from the asset database. They act as an interface for allocating system objects by taking the asset data as input. Allocations input can either be provided directly by the user or by requesting the asset database. See ( resource ).","title":"Resources"},{"location":"architecture_overview/#scene-middleware","text":"Scene middlewares are where node component resources are stored. They act as the communication layer between the scene and the internal systems. Because nodes can move in 3D space. The state of the Node is updated when it's position, rotation or scale has changed. The Scene Middlewares are the consumers of this state. When a Node has moved, they send events to internal systems to take this change into account. See ( scene middleware ).","title":"Scene middleware"},{"location":"architecture_overview/#asset-management","text":"All assets (3DModels, textures, user defined assets...) are stored in a unique local database. Asset files are written either in a human-readable format (.json, .obj, ...) or compressed (.png). However, when stored in the database, they are compiled into a blob that allows the engine to map it to internal objects with little efforts. This compilation is done during the build process, so we eliminate the runtime overhead of loading and decoding file formats. See ( asset database )","title":"Asset management"},{"location":"asset_database/","text":"Asset database The asset database is a database that stores : Engine assets as blob from human-readable format Engine assets dependencies Engine assets file metadata (compilation only, never requested by the engine) All assets are identified by a unique ID that is the hash code of the local path of the asset file. For example, if we specify at database compilation time that the asset root is \"E:/document/project/assets/\" then an asset file located at \"E:/document/project/assets/model/test.obj\" will be stored and requested by using \"model/test.obj\" as input for hash calculation. Hashes are calculated by using the djp2 function ( hash ). Engine assets Engine assets are stored as a blob chunk. The goal of the database is to provide an object format that needs the least amount of calculation for the engine to interpret it. So assets files are transformed from a human-readable format (or commonly used file extensions like .png, .obj) to one that is close to the engine object. For example, if we want to store an array of integers, the json array : { \"array\":[0,1,2,3,4,5] } will be compiled to it's packed memory representation : [size] (size_t 8 bytes) [0] (int 4 bytes) [1] (int 4 bytes) [2] (int 4 bytes) [3] (int 4 bytes) [4] (int 4 bytes) All custom defined asset files are written in json. The first field of every json file must be the type of the asset file. For example, if we define a material, the json file will start with : { \"type\": \"MATERIAL\", ... } Engine asset dependencies Asset dependencies are used to indicate all assets that are mentioned by the current asset. The system of compilation to blob is exactly the same as assets. The difference is that we are compiling the asset to provide a list of dependant asset ids. Asset dependencies can be recursively evaluated, it is up to the asset compilation implementation to decide it. Again, the goal is to be the most efficient possible when dependencies are read by the engine. The assets dependencies have their own table because : We don't always request them, because we have already requested an asset dependency that may have been evaluated recursively. In the future, we can have a case where we want to request dependencies in different format for the same asset. Engine asset metadata Asset metadata are all data that are irrelevant to the engine and only used or updated by tools. Asset compilation The asset compilation is the program executed to transform human-readable assets to engine assets. The program takes an asset configuration json file that lists all assets that are going to be compiled. All asset path are relative to the asset folder root. The asset compilation configuration can be used to compile multiple asset databases. This is useful when writing test cases for example. The configuration file has a \"common\" section that is used to compile asset that are required for the engine to startup. The required assets will be compiled for all database.","title":"AssetDatabase"},{"location":"asset_database/#asset-database","text":"The asset database is a database that stores : Engine assets as blob from human-readable format Engine assets dependencies Engine assets file metadata (compilation only, never requested by the engine) All assets are identified by a unique ID that is the hash code of the local path of the asset file. For example, if we specify at database compilation time that the asset root is \"E:/document/project/assets/\" then an asset file located at \"E:/document/project/assets/model/test.obj\" will be stored and requested by using \"model/test.obj\" as input for hash calculation. Hashes are calculated by using the djp2 function ( hash ).","title":"Asset database"},{"location":"asset_database/#engine-assets","text":"Engine assets are stored as a blob chunk. The goal of the database is to provide an object format that needs the least amount of calculation for the engine to interpret it. So assets files are transformed from a human-readable format (or commonly used file extensions like .png, .obj) to one that is close to the engine object. For example, if we want to store an array of integers, the json array : { \"array\":[0,1,2,3,4,5] } will be compiled to it's packed memory representation : [size] (size_t 8 bytes) [0] (int 4 bytes) [1] (int 4 bytes) [2] (int 4 bytes) [3] (int 4 bytes) [4] (int 4 bytes) All custom defined asset files are written in json. The first field of every json file must be the type of the asset file. For example, if we define a material, the json file will start with : { \"type\": \"MATERIAL\", ... }","title":"Engine assets"},{"location":"asset_database/#engine-asset-dependencies","text":"Asset dependencies are used to indicate all assets that are mentioned by the current asset. The system of compilation to blob is exactly the same as assets. The difference is that we are compiling the asset to provide a list of dependant asset ids. Asset dependencies can be recursively evaluated, it is up to the asset compilation implementation to decide it. Again, the goal is to be the most efficient possible when dependencies are read by the engine. The assets dependencies have their own table because : We don't always request them, because we have already requested an asset dependency that may have been evaluated recursively. In the future, we can have a case where we want to request dependencies in different format for the same asset.","title":"Engine asset dependencies"},{"location":"asset_database/#engine-asset-metadata","text":"Asset metadata are all data that are irrelevant to the engine and only used or updated by tools.","title":"Engine asset metadata"},{"location":"asset_database/#asset-compilation","text":"The asset compilation is the program executed to transform human-readable assets to engine assets. The program takes an asset configuration json file that lists all assets that are going to be compiled. All asset path are relative to the asset folder root. The asset compilation configuration can be used to compile multiple asset databases. This is useful when writing test cases for example. The configuration file has a \"common\" section that is used to compile asset that are required for the engine to startup. The required assets will be compiled for all database.","title":"Asset compilation"},{"location":"gpu/","text":"The GPU module is responsible for : Providing convenient systems to allocate, free and write to GPU memory chunks. Deferring commands that needs synchronization with the gpu. Abstracting graphics objects such as Shader, Material ... Architecture The GPU module is composed of : GPUHeap : allocates a huge chunk of GPU memory and cut a slice into it based on vulkan constraint. BufferAllocator : allocates and holds token of vulkan buffer objects. BufferEvents : stores all GPU operations that are deferred to be executed on a command buffer. BufferMemory : acts as an entry point for memory allocation and read/write event push. GraphicsHeap : stores token of graphics objects. GraphicsAllocator : allocates abstracted graphics objects. GraphicsBinder : uses graphics objects to execute draw commands. On initialization, the GPU systems creates two command buffer objects that are responsible for ordering the GPU to execute draw operations or buffer copy operations. Before the start of the frame, these command buffers are flushed from previous commands. At the end of the frame, these command buffers are submitted in the following order : Transfer command buffer : responsible for buffer copy operations and texture layout transition. Graphics command buffer : responsible for binding graphics objects and draw vertices. GPU memory allocation The GPU memory allocation is done by allocating one or more huge chunks of memory on the GPU. Any GPU allocation or deallocation works with a slice of memory of the huge chunk. Memory requirements such as size and alignment is provided by the vulkan API. From these constraints, we manually identify and cut a slice of memory from the GPUHeap. Every heap has its own memory type defined by the types of memory requested. Buffer A Buffer is a general purpose memory (like if you allocate memory from CPU). A buffer can be of two type : _Host means that the memory pointer can be directly mapped and visible from CPU. The memory is still allocated on the GPU but reading from it may be less efficient. _GPU means that the memory pointer cannot be visible from CPU. In order to read/write to it, we must create a temporary Host buffer and execute command to transfer data from/to the GPU. All buffer allocations are instant. Ask vulkan for memory requirements. Cut a memory from an already allocated buffer. BufferHost read/write are instantaneous because their memory type corresponds to a host heap chunk that has already been mapped. BufferGPU read/write have an additional level of indirection as a temporary Host buffer must be created and a gpu operation must be registered to a command buffer. Image An Image is allocated the same way as a Buffer. Instead of passing a size in bytes, we use an image format object. struct ImageFormat { VkImageAspectFlags imageAspect; VkImageType imageType; ImageUsageFlag imageUsage; VkFormat format; v3ui extent; uint32 mipLevels; uint32 arrayLayers; VkSampleCountFlagBits samples; }; WARNING : mipLevels and arrayLayers are not supported yet. The vulkan api let the user manage an internal state of an image called ImageLayout. It acts as a flag to indicates what operations are allowed on the image. The image usage flag indicates where this image will be used (as a shader parameter, or as the target of a render pass) . This flags is the only parameter used to set the underlying image layout. Because the vulkan API needs a specific image layout value when the image is being read or written to, every operation on image must be deferred to execute layout transition before and after. BufferEvents step The BufferEvents stores all deferred GPU buffer read/write and texture copy events. These events are consumed and the beginning of a frame by the transfer command buffer. Events are consumed in the following order : Image allocation event to execute image layout transition to it's target layout. Read/Write to BufferGPU. Read/Write to ImageGPU. WARNING : It is very important that image host and gpu allocation events are processed before image copy operations because further events assume that the image layout of the image is the targetted one. Image allocation When an image is allocated, its image layout is undefined. These events execute image layout transition based on the image imageUsage. ImageLayout transition from unknown state to desired imageUsage. Read/Write to BufferGPU Push copy commands to the temporary buffer (as described in the buffer section ) Read/Write to ImageGPU Image layout transition from desired image usage to transfert_src or transfert_dst depending on the operation. Copy command. Image layout transition from transfert_src or transfert_dst to desired image usage. Graphics abstraction All graphics abstraction objects describe how a draw command is performed. Allocation of any graphics object is done by having a reference to the buffer memory object because they can cause buffer or image allocation. Graphics abstraction is a layer on top of the GPU memory layer. There is no dependencies between all these objects. This choice has been made to not enforce any hierarchy. The dependency between objects is ensured by the graphics binding. TextureGPU: A TextureGPU is an Image with a description of which mip map or array layer is selected. GraphicsPass: The GraphicsPass is the render texture attachments that will be used for drawing. Texture attachment supported are colour attachment and depth attachment. Shader: A Shader is a program that is executed against a GraphicsPass and a set of ShaderParameters. On allocation, a shader is configured to decide whether ztest and zwrite is perfored. ShaderModule: A ShaderModule is the compiled small unit of (vertex|fragment) shader pass executed by the Shader. ShaderLayout: The ShaderLayout indicate the format of all parameters of the Shader (including vertex format). It can be seen as the Reflection data of a Shader. ShaderParameter: A ShaderParameter is a buffer or image that is bound at a certain location of the shader to be used by the program. ShaderParameters can be UniformHost, UniformGPU or TextureGPU. Material: A Material is an array of ShaderParameters. Graphics binding The graphics binding object allows notifying to the GPU all data needed to perform a draw call. Binding draw commands are sent to the graphics command buffer. A specific binding order must be respected as validation is performed for every binding. Once an object has been bound, it will still be bound until another one takes its place. This means that we don't have to re-bind the graphics pass or the Shader when we bind another set of ShaderParameters. ShaderParameters can be bound at any position, they also stay bound at the desired index until another one takes place. Presentation The presentation is a direct usage of the GraphicsBinding. The presentation layer consists of a SwapChain render the input render texture to a present texture. Present textures are allocated internally by the vulkan API by providing a native handle of the window. The SwapChain allocates all GraphicsObjects necessary for drawing the render texture to a present texture. The presentation module is optional, it is up to the consumer to decide whether or not to allocate one and include it the GraphicsBinding loop. Input : Compiled image quad blit shader module. Already allocated render texture. Window resize event When the native window is resized internal present textures are reallocated to fit the window dimensions.","title":"GPU"},{"location":"gpu/#architecture","text":"The GPU module is composed of : GPUHeap : allocates a huge chunk of GPU memory and cut a slice into it based on vulkan constraint. BufferAllocator : allocates and holds token of vulkan buffer objects. BufferEvents : stores all GPU operations that are deferred to be executed on a command buffer. BufferMemory : acts as an entry point for memory allocation and read/write event push. GraphicsHeap : stores token of graphics objects. GraphicsAllocator : allocates abstracted graphics objects. GraphicsBinder : uses graphics objects to execute draw commands. On initialization, the GPU systems creates two command buffer objects that are responsible for ordering the GPU to execute draw operations or buffer copy operations. Before the start of the frame, these command buffers are flushed from previous commands. At the end of the frame, these command buffers are submitted in the following order : Transfer command buffer : responsible for buffer copy operations and texture layout transition. Graphics command buffer : responsible for binding graphics objects and draw vertices.","title":"Architecture"},{"location":"gpu/#gpu-memory-allocation","text":"The GPU memory allocation is done by allocating one or more huge chunks of memory on the GPU. Any GPU allocation or deallocation works with a slice of memory of the huge chunk. Memory requirements such as size and alignment is provided by the vulkan API. From these constraints, we manually identify and cut a slice of memory from the GPUHeap. Every heap has its own memory type defined by the types of memory requested.","title":"GPU memory allocation"},{"location":"gpu/#buffer","text":"A Buffer is a general purpose memory (like if you allocate memory from CPU). A buffer can be of two type : _Host means that the memory pointer can be directly mapped and visible from CPU. The memory is still allocated on the GPU but reading from it may be less efficient. _GPU means that the memory pointer cannot be visible from CPU. In order to read/write to it, we must create a temporary Host buffer and execute command to transfer data from/to the GPU. All buffer allocations are instant. Ask vulkan for memory requirements. Cut a memory from an already allocated buffer. BufferHost read/write are instantaneous because their memory type corresponds to a host heap chunk that has already been mapped. BufferGPU read/write have an additional level of indirection as a temporary Host buffer must be created and a gpu operation must be registered to a command buffer.","title":"Buffer"},{"location":"gpu/#image","text":"An Image is allocated the same way as a Buffer. Instead of passing a size in bytes, we use an image format object. struct ImageFormat { VkImageAspectFlags imageAspect; VkImageType imageType; ImageUsageFlag imageUsage; VkFormat format; v3ui extent; uint32 mipLevels; uint32 arrayLayers; VkSampleCountFlagBits samples; }; WARNING : mipLevels and arrayLayers are not supported yet. The vulkan api let the user manage an internal state of an image called ImageLayout. It acts as a flag to indicates what operations are allowed on the image. The image usage flag indicates where this image will be used (as a shader parameter, or as the target of a render pass) . This flags is the only parameter used to set the underlying image layout. Because the vulkan API needs a specific image layout value when the image is being read or written to, every operation on image must be deferred to execute layout transition before and after.","title":"Image"},{"location":"gpu/#bufferevents-step","text":"The BufferEvents stores all deferred GPU buffer read/write and texture copy events. These events are consumed and the beginning of a frame by the transfer command buffer. Events are consumed in the following order : Image allocation event to execute image layout transition to it's target layout. Read/Write to BufferGPU. Read/Write to ImageGPU. WARNING : It is very important that image host and gpu allocation events are processed before image copy operations because further events assume that the image layout of the image is the targetted one.","title":"BufferEvents step"},{"location":"gpu/#image-allocation","text":"When an image is allocated, its image layout is undefined. These events execute image layout transition based on the image imageUsage. ImageLayout transition from unknown state to desired imageUsage.","title":"Image allocation"},{"location":"gpu/#readwrite-to-buffergpu","text":"Push copy commands to the temporary buffer (as described in the buffer section )","title":"Read/Write to BufferGPU"},{"location":"gpu/#readwrite-to-imagegpu","text":"Image layout transition from desired image usage to transfert_src or transfert_dst depending on the operation. Copy command. Image layout transition from transfert_src or transfert_dst to desired image usage.","title":"Read/Write to ImageGPU"},{"location":"gpu/#graphics-abstraction","text":"All graphics abstraction objects describe how a draw command is performed. Allocation of any graphics object is done by having a reference to the buffer memory object because they can cause buffer or image allocation. Graphics abstraction is a layer on top of the GPU memory layer. There is no dependencies between all these objects. This choice has been made to not enforce any hierarchy. The dependency between objects is ensured by the graphics binding. TextureGPU: A TextureGPU is an Image with a description of which mip map or array layer is selected. GraphicsPass: The GraphicsPass is the render texture attachments that will be used for drawing. Texture attachment supported are colour attachment and depth attachment. Shader: A Shader is a program that is executed against a GraphicsPass and a set of ShaderParameters. On allocation, a shader is configured to decide whether ztest and zwrite is perfored. ShaderModule: A ShaderModule is the compiled small unit of (vertex|fragment) shader pass executed by the Shader. ShaderLayout: The ShaderLayout indicate the format of all parameters of the Shader (including vertex format). It can be seen as the Reflection data of a Shader. ShaderParameter: A ShaderParameter is a buffer or image that is bound at a certain location of the shader to be used by the program. ShaderParameters can be UniformHost, UniformGPU or TextureGPU. Material: A Material is an array of ShaderParameters.","title":"Graphics abstraction"},{"location":"gpu/#graphics-binding","text":"The graphics binding object allows notifying to the GPU all data needed to perform a draw call. Binding draw commands are sent to the graphics command buffer. A specific binding order must be respected as validation is performed for every binding. Once an object has been bound, it will still be bound until another one takes its place. This means that we don't have to re-bind the graphics pass or the Shader when we bind another set of ShaderParameters. ShaderParameters can be bound at any position, they also stay bound at the desired index until another one takes place.","title":"Graphics binding"},{"location":"gpu/#presentation","text":"The presentation is a direct usage of the GraphicsBinding. The presentation layer consists of a SwapChain render the input render texture to a present texture. Present textures are allocated internally by the vulkan API by providing a native handle of the window. The SwapChain allocates all GraphicsObjects necessary for drawing the render texture to a present texture. The presentation module is optional, it is up to the consumer to decide whether or not to allocate one and include it the GraphicsBinding loop. Input : Compiled image quad blit shader module. Already allocated render texture.","title":"Presentation"},{"location":"gpu/#window-resize-event","text":"When the native window is resized internal present textures are reallocated to fit the window dimensions.","title":"Window resize event"},{"location":"render/","text":"The Render module is the 3D renderer of the engine. It registers all graphics objects and organize them in a hierarchy to call GPU graphics bindings against them. The render module creates an internal 2D render target texture and draw the hierarchy to it every frame. Architecture The render module is composed of : ColorStep : responsible for the graphics passes supported by the module. D3RendererHeap : holds values of the render hierarchy. D3RendererAllocator : ensure the coherence of the render hierarchy (links between graphics objects). D3RendererEvents : acts as a buffer that store references of all renderable objects that will update it's model matrix. Data model * RenderableObject * Mesh * ShaderUniformBufferHostParameter (model) * Mesh * BufferGPU (vertices_buffer) * BufferGPU (indices_buffer) * ShaderIndex * Shader * ShaderLayout (ShaderIndex)(1)--(0..*)(Material)(1)--(0..*)(RenderableObject) (RenderableObject)(1)--(1)(Mesh) Mesh: Holds reference to a vertex and index GPU buffer. It is up to the render module consumer to define the vertex buffer format. It must match with the shader vertex input. By default, mesh buffers are GPU allocated because we suppose that their value won't be modified often. RenderableObject: The renderable object is the representation of an object in 3D space with its shape. It holds a reference to a Mesh and a model matrix. The model matrix is always host shader parameter because it's value is subject to change often. Camera: The camera is from where the whole hierarchy is rendered. WARNING : only one instance of camera can be instantiated for now. ShaderIndex: A shader index is a Shader with a layout and an execution order. Render hierarchy Every frame, the render hierarchy is bound to a GraphicsBinder by following an order : This hierarchy imposes that global buffer are bound before everything else and that the model buffer is bound at the very end. This constraint is translated in the shader source code : struct Camera { mat4 view; mat4 projection; }; layout(set = 0, binding = 0) uniform camera { Camera cam; }; // insert all material buffer or samplers layout(set = END, binding = 0) uniform model { mat4 mod; }; Shader ordering ShaderIndex inside the hierarchy are ordered by their execution order. This will come useful when we want to add transparency pass for example. Model matrix update Once a RenderableObject has been allocated, consumers of the render module can notify the renderer that an object has moved (pos, rot, scale) by sending a ModelUpdateEvent. When consumed, the ModelUpdateEvent will update the model buffer by the inputted matrix.","title":"Render"},{"location":"render/#architecture","text":"The render module is composed of : ColorStep : responsible for the graphics passes supported by the module. D3RendererHeap : holds values of the render hierarchy. D3RendererAllocator : ensure the coherence of the render hierarchy (links between graphics objects). D3RendererEvents : acts as a buffer that store references of all renderable objects that will update it's model matrix.","title":"Architecture"},{"location":"render/#data-model","text":"* RenderableObject * Mesh * ShaderUniformBufferHostParameter (model) * Mesh * BufferGPU (vertices_buffer) * BufferGPU (indices_buffer) * ShaderIndex * Shader * ShaderLayout (ShaderIndex)(1)--(0..*)(Material)(1)--(0..*)(RenderableObject) (RenderableObject)(1)--(1)(Mesh) Mesh: Holds reference to a vertex and index GPU buffer. It is up to the render module consumer to define the vertex buffer format. It must match with the shader vertex input. By default, mesh buffers are GPU allocated because we suppose that their value won't be modified often. RenderableObject: The renderable object is the representation of an object in 3D space with its shape. It holds a reference to a Mesh and a model matrix. The model matrix is always host shader parameter because it's value is subject to change often. Camera: The camera is from where the whole hierarchy is rendered. WARNING : only one instance of camera can be instantiated for now. ShaderIndex: A shader index is a Shader with a layout and an execution order.","title":"Data model"},{"location":"render/#render-hierarchy","text":"Every frame, the render hierarchy is bound to a GraphicsBinder by following an order : This hierarchy imposes that global buffer are bound before everything else and that the model buffer is bound at the very end. This constraint is translated in the shader source code : struct Camera { mat4 view; mat4 projection; }; layout(set = 0, binding = 0) uniform camera { Camera cam; }; // insert all material buffer or samplers layout(set = END, binding = 0) uniform model { mat4 mod; };","title":"Render hierarchy"},{"location":"render/#shader-ordering","text":"ShaderIndex inside the hierarchy are ordered by their execution order. This will come useful when we want to add transparency pass for example.","title":"Shader ordering"},{"location":"render/#model-matrix-update","text":"Once a RenderableObject has been allocated, consumers of the render module can notify the renderer that an object has moved (pos, rot, scale) by sending a ModelUpdateEvent. When consumed, the ModelUpdateEvent will update the model buffer by the inputted matrix.","title":"Model matrix update"},{"location":"render_middleware/","text":"The render middleware is the interface between the scene and the render system. It allocates scene components and update their render state when associated nodes are moving. Architecture CameraComponent: Attach a camera object to a node. MeshRendererComponentUnit: Allocate render components MeshRendererComponent The meshrenderer component uses a material resource and a mesh resource to allocate and link a renderable object. 3D position update Every frame, the system checks if any of the meshrenderer components and camera component associated node has moved. If that's the case, then a model matrix update event is sent to the render system.","title":"Render middleware"},{"location":"render_middleware/#architecture","text":"CameraComponent: Attach a camera object to a node. MeshRendererComponentUnit: Allocate render components","title":"Architecture"},{"location":"render_middleware/#meshrenderercomponent","text":"The meshrenderer component uses a material resource and a mesh resource to allocate and link a renderable object.","title":"MeshRendererComponent"},{"location":"render_middleware/#3d-position-update","text":"Every frame, the system checks if any of the meshrenderer components and camera component associated node has moved. If that's the case, then a model matrix update event is sent to the render system.","title":"3D position update"},{"location":"render_resource/","text":"Data model","title":"Render resource"},{"location":"render_resource/#data-model","text":"","title":"Data model"},{"location":"resource/","text":"A Resource is an instantiated object that load data from the asset database to allocate a system internal object. The resource object doesn't have any logic, it simply holds references to the allocated internal object. Architecture Every resource is associated to an allocation unit. This allocation unit is in charge of handling all allocation and deallocation inputs. If the criteria is met, it stores the event in a buffer that is later consumed by the main loop. Allocation/Deallocation When an allocation is requested, the allocation unit generate a resource token that is returned to the caller. Also, an internal allocation event is generated. The consumer can retrieve the allocated resource by providing the returned token. When a deallocation is requested, the allocation unit generate a deallocation event. The token is invalid when the event is consumed and that the resource has been freed. The same resource can be allocated multiple times. When that happens, the same resource token is returned and the usage counter in incremented by one. Deallocation request make the counter decrease by one. As soon as the counter reaches zero, the deallocation event is generated. Allocation modes The resource allocation input can be provided by two ways: Requested to the database: If the resource input is requested to the database, the caller provide the asset path used by the database to retrieve the asset. Provided inline: If the resource input is provided inline, the caller provide the same data as if it were retrieved by the database. Allocation events are processed in the following order for a single allocation unit : Resource identification All resources are associated to an internal ID. When the resource input is provided inline, the resource ID is given by the caller. When the resource input is provided by the database, the resource ID is computed by the hash of the asset path. Resource dependencies Resources can be linked together (for example, a Material is linked to Shader) introducing an allocation and deallocation execution order. A goal of the allocation units is to handle the recursive allocation/deallocation of linked internal system objects, so that the internal systems can blindly execute requests from the allocation unit. If resource A needs resource B to work, then the allocation order will be : (B) -> (A). And the deallocation order : ( A) -> (B). When the resource allocation input is provided inline, it is up to the caller to provide input for the requested resource and it's dependencies. When the resource allocation input is provided by the database, then an additional asset database request is performed to retrieve asset ID dependencies.","title":"Resource"},{"location":"resource/#architecture","text":"Every resource is associated to an allocation unit. This allocation unit is in charge of handling all allocation and deallocation inputs. If the criteria is met, it stores the event in a buffer that is later consumed by the main loop.","title":"Architecture"},{"location":"resource/#allocationdeallocation","text":"When an allocation is requested, the allocation unit generate a resource token that is returned to the caller. Also, an internal allocation event is generated. The consumer can retrieve the allocated resource by providing the returned token. When a deallocation is requested, the allocation unit generate a deallocation event. The token is invalid when the event is consumed and that the resource has been freed. The same resource can be allocated multiple times. When that happens, the same resource token is returned and the usage counter in incremented by one. Deallocation request make the counter decrease by one. As soon as the counter reaches zero, the deallocation event is generated.","title":"Allocation/Deallocation"},{"location":"resource/#allocation-modes","text":"The resource allocation input can be provided by two ways: Requested to the database: If the resource input is requested to the database, the caller provide the asset path used by the database to retrieve the asset. Provided inline: If the resource input is provided inline, the caller provide the same data as if it were retrieved by the database. Allocation events are processed in the following order for a single allocation unit :","title":"Allocation modes"},{"location":"resource/#resource-identification","text":"All resources are associated to an internal ID. When the resource input is provided inline, the resource ID is given by the caller. When the resource input is provided by the database, the resource ID is computed by the hash of the asset path.","title":"Resource identification"},{"location":"resource/#resource-dependencies","text":"Resources can be linked together (for example, a Material is linked to Shader) introducing an allocation and deallocation execution order. A goal of the allocation units is to handle the recursive allocation/deallocation of linked internal system objects, so that the internal systems can blindly execute requests from the allocation unit. If resource A needs resource B to work, then the allocation order will be : (B) -> (A). And the deallocation order : ( A) -> (B). When the resource allocation input is provided inline, it is up to the caller to provide input for the requested resource and it's dependencies. When the resource allocation input is provided by the database, then an additional asset database request is performed to retrieve asset ID dependencies.","title":"Resource dependencies"},{"location":"scene/","text":"A node hierarchy where every node can have components. The node hierarchy allows positioning points in 3D space where parent movement influence the child position. Components are functionality attached to the node that communicate with internal systems via the scene middleware. Architecture Node: a point in 3D space. SceneTree: the hierarchical view of nodes. All node movement must be done through the SceneTree. Component: a component is a typed external object associated to a node. Scene: an object that link nodes to components. It acts as an interface of the scene tree. Scene hierarchical update The node is composed of a local transform (position, rotation, scale) and a local to world matrix. When updating a node transform, what we change is the local transform. The local to world matrix is recalculated on the fly, only when needed. The local to world matrix value is cached until the transform change again. Because nodes are organized in a tree, the parent movement affect the child position. When a node parent position is set, this change is propagated recursively into the tree. This propagation is done instantaneously. When a node transform has changed, the internal state of the node indicates that this frame, the node has changed. This state can be used by middleware to check if a node has moved or not. WARNING: The state of the node is cleared every frame. Component allocation The component is a structure that contains a type and an external object token. When we want to add a component to a node, it's external resource has already been allocated by the scene middleware (or at least, a token has been generated). So, we provide this token to the node component allocation. Component deallocation events Because component deallocation can be triggered manually by the user logic on indirectly by removing a node, component deallocation events are stored to an event buffer. From the point of view of the scene, we have no idea of what is the external component object allocated or what is its purpose. So we need to send notifications when the component is removed. To do so, the component deallocation event buffer can be consumed to execute functions accordingly to the component type. WARNING : The component deallocation event buffer is cleared at the end of every frame. If events are not consumed before that, then events will be lost.","title":"Scene"},{"location":"scene/#architecture","text":"Node: a point in 3D space. SceneTree: the hierarchical view of nodes. All node movement must be done through the SceneTree. Component: a component is a typed external object associated to a node. Scene: an object that link nodes to components. It acts as an interface of the scene tree.","title":"Architecture"},{"location":"scene/#scene-hierarchical-update","text":"The node is composed of a local transform (position, rotation, scale) and a local to world matrix. When updating a node transform, what we change is the local transform. The local to world matrix is recalculated on the fly, only when needed. The local to world matrix value is cached until the transform change again. Because nodes are organized in a tree, the parent movement affect the child position. When a node parent position is set, this change is propagated recursively into the tree. This propagation is done instantaneously. When a node transform has changed, the internal state of the node indicates that this frame, the node has changed. This state can be used by middleware to check if a node has moved or not. WARNING: The state of the node is cleared every frame.","title":"Scene hierarchical update"},{"location":"scene/#component-allocation","text":"The component is a structure that contains a type and an external object token. When we want to add a component to a node, it's external resource has already been allocated by the scene middleware (or at least, a token has been generated). So, we provide this token to the node component allocation.","title":"Component allocation"},{"location":"scene/#component-deallocation-events","text":"Because component deallocation can be triggered manually by the user logic on indirectly by removing a node, component deallocation events are stored to an event buffer. From the point of view of the scene, we have no idea of what is the external component object allocated or what is its purpose. So we need to send notifications when the component is removed. To do so, the component deallocation event buffer can be consumed to execute functions accordingly to the component type. WARNING : The component deallocation event buffer is cleared at the end of every frame. If events are not consumed before that, then events will be lost.","title":"Component deallocation events"},{"location":"scene_middleware/","text":"The SceneMiddleware is the indirection layer between the Scene and the internal Systems. When a component is added to a node, the component internal resource is allocated from one of the scene middlewares. Scene middlewares also act as interface for scene component deallocation event. The scene middlewares can consume the state of the node to tell whether a specific node has changed this frame, to notify internal systems. Architecture SceneMiddleware: holds functions for component deallocation XXX Component Unit: responsible for deferred allocation of component XXX Middleware: the system that communicate node events to internal systems Component objects allocation Component objects are allocated by the user by using the same deferred allocation mechanism as the resources. However, every component objects has its ID that is generated by the unit. WARNING : Because component objects may depend of some resources, resources allocation must be exectued before. The same logic goes for deallocation. Scene node event push Middlewares hold an array of structure that links the node to the component object. When necessary, the middleware can iterate over this array to check the state of the node. If criteria are met (for example: the node has moved during the last frame), then a notification can be sent to the internal system.","title":"Scene Middleware"},{"location":"scene_middleware/#architecture","text":"SceneMiddleware: holds functions for component deallocation XXX Component Unit: responsible for deferred allocation of component XXX Middleware: the system that communicate node events to internal systems","title":"Architecture"},{"location":"scene_middleware/#component-objects-allocation","text":"Component objects are allocated by the user by using the same deferred allocation mechanism as the resources. However, every component objects has its ID that is generated by the unit. WARNING : Because component objects may depend of some resources, resources allocation must be exectued before. The same logic goes for deallocation.","title":"Component objects allocation"},{"location":"scene_middleware/#scene-node-event-push","text":"Middlewares hold an array of structure that links the node to the component object. When necessary, the middleware can iterate over this array to check the state of the node. If criteria are met (for example: the node has moved during the last frame), then a notification can be sent to the internal system.","title":"Scene node event push"}]}